{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import json \n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Helper functions \n",
    "def create_df(path, market_selection, date_range_selection):\n",
    "    df_product = pd.DataFrame(columns=['product_id', 'market', 'extraction_date', 'name', 'vendor', \n",
    "                                       'ships_from', 'ships_to', 'price', 'price_eur', 'info', 'macro_category',\n",
    "                                       'micro_category','feedback'])\n",
    "    df_vendor = pd.DataFrame(columns=['name', 'market', 'extraction_date', 'score', 'score_normalized', \n",
    "                                      'registration_date', 'registration_date_deviation', 'last_login', \n",
    "                                      'last_login_deviation', 'sales', 'info', 'pgp', 'feedback'])\n",
    "    \n",
    "    \n",
    "    for market in market_selection:\n",
    "        dates_in_data = get_dates(path, [market])[2]\n",
    "        retrieve_dates = [date for date in dates_in_data \n",
    "                          if (date >= date_range_selection[0]) and (date <= date_range_selection[1])]\n",
    "        \n",
    "        for date in retrieve_dates:            \n",
    "            file_path_product = path + market + '/' + date + '/' + date + '_' + market + '_product.txt'\n",
    "            file_path_vendor = path + market + '/' + date + '/' + date + '_' + market + '_vendor.txt'\n",
    "            import_data_product = None\n",
    "            import_data_vendor = None\n",
    "            \n",
    "            # Product\n",
    "            if os.path.isfile(file_path_product):\n",
    "                with open(file_path_product) as json_file:\n",
    "                    import_data_product = json.load(json_file)\n",
    "                    \n",
    "                for item in import_data_product:\n",
    "                    row = [item,  # product_id\n",
    "                           import_data_product[item]['web_page']['market'],\n",
    "                           import_data_product[item]['web_page']['date'],\n",
    "                           import_data_product[item]['page_data']['name'],\n",
    "                           import_data_product[item]['page_data']['vendor'],\n",
    "                           import_data_product[item]['page_data']['ships_from'],\n",
    "                           import_data_product[item]['page_data']['ships_to'],\n",
    "                           import_data_product[item]['page_data']['price'],\n",
    "                           import_data_product[item]['page_data']['price_eur'],\n",
    "                           import_data_product[item]['page_data']['info'],\n",
    "                           import_data_product[item]['page_data']['macro_category'],\n",
    "                           import_data_product[item]['page_data']['micro_category'],\n",
    "                           import_data_product[item]['page_data']['feedback']\n",
    "                          ]\n",
    "                    df_product.loc[len(df_product)] = row\n",
    "\n",
    "            \n",
    "            # Vendor\n",
    "            if os.path.isfile(file_path_vendor):\n",
    "                with open(file_path_vendor) as json_file:\n",
    "                    import_data_vendor = json.load(json_file)\n",
    "                for item in import_data_vendor:\n",
    "                    row = [item,  # name\n",
    "                           import_data_vendor[item]['web_page']['market'],\n",
    "                           import_data_vendor[item]['web_page']['date'],\n",
    "                           import_data_vendor[item]['page_data']['score'],\n",
    "                           import_data_vendor[item]['page_data']['score_normalized'],\n",
    "                           import_data_vendor[item]['page_data']['registration'],\n",
    "                           import_data_vendor[item]['page_data']['registration_deviation'],\n",
    "                           import_data_vendor[item]['page_data']['last_login'],\n",
    "                           import_data_vendor[item]['page_data']['last_login_deviation'],\n",
    "                           import_data_vendor[item]['page_data']['sales'],\n",
    "                           import_data_vendor[item]['page_data']['info'],\n",
    "                           import_data_vendor[item]['page_data']['pgp'],\n",
    "                           import_data_vendor[item]['page_data']['feedback']\n",
    "                          ]\n",
    "                    df_vendor.loc[len(df_vendor)] = row\n",
    "    \n",
    "    return df_product, df_vendor\n",
    "\n",
    "def get_market(path):\n",
    "    \"\"\"Returns all the markerts in the folder\"\"\"\n",
    "    markets =  next(os.walk(path))[1]\n",
    "    markets.remove('item_id')\n",
    "    return markets\n",
    "\n",
    "\n",
    "def get_dates(path, markets):\n",
    "    \"\"\"Get the min and max date to make the range possible \"\"\"\n",
    "    \n",
    "    list_of_dates = [] \n",
    "    for market in markets:\n",
    "        market_path = path + '/' + market\n",
    "        list_of_dates += next(os.walk(market_path))[1]\n",
    "    unique_dates_list = list(set(list_of_dates))\n",
    "    return min(list_of_dates), max(list_of_dates), sorted(unique_dates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "json_path = \"PATH TO MAIN FOLDER WITH JSON FILES\" # FILL IN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert\n",
    "all_markets = get_market(path)\n",
    "all_dates = get_dates(path, all_markets)\n",
    "df_product, df_vendor = create_df(path, all_markets, all_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix mistake in PGP (is too be solved next week)\n",
    "def replace_n(pgp):\n",
    "    try:\n",
    "        return pgp.replace('\\n', '')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_vendor['pgp'] = df_vendor.apply(lambda x: replace_n(x['pgp']),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df_vendor.to_csv('2020_06_09_df_vendor.csv', index=False) \n",
    "df_product.to_csv('2020_06_09_df_product.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
